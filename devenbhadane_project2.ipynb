{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing PIE Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting text files to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_csv(txt_file, csv_file, delimiter=' '):\n",
    "    with open(txt_file, 'r') as infile:\n",
    "        with open(csv_file, 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            for line in infile:\n",
    "                # Assuming each line contains data separated by a delimiter\n",
    "                # You can adjust the delimiter as per your text file structure\n",
    "                data = line.strip().split(delimiter)\n",
    "                writer.writerow(data)\n",
    "\n",
    "# Converting each text file to csv one-by-one\n",
    "txt_to_csv('/home/baa223/Badri/deeplearning/dm_project/dm_project/PIE_32x32/PIE_32x32/StTrainFile.txt',\n",
    "            '/home/baa223/Badri/deeplearning/dm_project/dm_project/PIE_32x32/PIE_32x32/train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting CSV file to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save the images\n",
    "output_dir = 'PIE_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file = '/home/baa223/Badri/deeplearning/dm_project/dm_project/PIE_32x32 (old)/PIE_32x32 (old)/test.csv'\n",
    "\n",
    "# Open the CSV file\n",
    "with open(csv_file, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header row\n",
    "    for idx, row in enumerate(reader):\n",
    "        # Extract image pixel values and class label\n",
    "        pixel_values = [float(value) for value in row[:-1]]\n",
    "        label = int(row[-1])\n",
    "\n",
    "        # Convert pixel values to 32x32 image\n",
    "        image_array = np.array(pixel_values, dtype=np.float32).reshape(32, 32)\n",
    "        image = Image.fromarray((image_array * 255).astype(np.uint8))\n",
    "\n",
    "        # Rotate the image 90 degrees to the left\n",
    "        image = image.rotate(-90, expand=True)\n",
    "\n",
    "        # Create a directory for the class if it doesn't exist\n",
    "        class_dir = os.path.join(output_dir, f'class_{label}')\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # Save the image with appropriate filename\n",
    "        image_filename = f'PIE_image_{idx}.png'\n",
    "        image_path = os.path.join(class_dir, image_filename)\n",
    "        image.save(image_path)\n",
    "\n",
    "        print(f'Saved image {idx} with label {label} to {image_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import random_split\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "param = {\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 100,\n",
    "    'weight_decay': 2e-5,\n",
    "    'num_workers': 8,\n",
    "    'classes': None,\n",
    "    # set the dataset name to either 'mnist', 'cifar10' or 'pie' and then rerun all the cells\n",
    "    # from Training the model section\n",
    "    'dataset_name': 'cifar10',\n",
    "    'model_name': '',\n",
    "}\n",
    "\n",
    "# setting the name for model\n",
    "param['model_name'] = 'resnet50' + '_' + param['dataset_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name, data_transform1, data_transform2):\n",
    "     # If the dataset is CIFAR10\n",
    "    if dataset_name == 'cifar10':\n",
    "        param['classes'] = 10\n",
    "        param['epochs'] = 60\n",
    "\n",
    "        data_transform1 = transforms.Compose(data_transform1)\n",
    "        data_transform2 = transforms.Compose(data_transform2)\n",
    "\n",
    "        # Downloading the CIFAR10 training dataset if its not present\n",
    "        visual_dataset = torchvision.datasets.CIFAR10(root='dm_project/', train=False,\n",
    "                                                     download=False, transform=transforms.ToTensor())\n",
    "        train_dataset = torchvision.datasets.CIFAR10(root='dm_project/', train=True,\n",
    "                                                     download=True, transform=data_transform1)\n",
    "        test_dataset = torchvision.datasets.CIFAR10(root='dm_project/', train=False,\n",
    "                                                    download=False, transform=data_transform2)\n",
    "    elif dataset_name == 'mnist':\n",
    "        param['classes'] = 10\n",
    "        param['epochs'] = 50\n",
    "        \n",
    "        # Converting the MNIST dataset images from 1 to 3 channels\n",
    "        new_transform1 = [transforms.Grayscale(num_output_channels=3)] + data_transform1\n",
    "        new_transform2 = [transforms.Grayscale(num_output_channels=3)] + data_transform2\n",
    "\n",
    "        data_transform1 = transforms.Compose(new_transform1)\n",
    "        data_transform2 = transforms.Compose(new_transform2)\n",
    "\n",
    "        # Downloading the MNIST training dataset if its not present\n",
    "        visual_dataset = torchvision.datasets.MNIST(root='dm_project/', train=False,\n",
    "                                                    download=False, transform=transforms.ToTensor())\n",
    "        train_dataset = torchvision.datasets.MNIST(root='dm_project/', train=True,\n",
    "                                                   download=True, transform=data_transform1)\n",
    "        test_dataset = torchvision.datasets.MNIST(root='dm_project/', train=False,\n",
    "                                                  download=False, transform=data_transform2)\n",
    "    elif dataset_name == 'pie':\n",
    "        param['classes'] = 68\n",
    "        param['epochs'] = 100\n",
    "        \n",
    "        # Converting the PIE dataset images from 1 to 3 channels\n",
    "        new_transform1 = [transforms.Grayscale(num_output_channels=3)] + data_transform1\n",
    "        new_transform2 = [transforms.Grayscale(num_output_channels=3)] + data_transform2\n",
    "        \n",
    "        data_transform1 = transforms.Compose(new_transform1)\n",
    "        data_transform2 = transforms.Compose(new_transform2)\n",
    "\n",
    "        # Load the PIE training dataset from local directory\n",
    "        # where the code file is present\n",
    "        visual_dataset = torchvision.datasets.ImageFolder(root='/home/baa223/Badri/deeplearning/dm_project/dm_project/PIE_32x32/train',\n",
    "                                                           transform=transforms.ToTensor())\n",
    "        train_dataset = torchvision.datasets.ImageFolder(root='/home/baa223/Badri/deeplearning/dm_project/dm_project/PIE_32x32/train',\n",
    "                                                          transform=data_transform1)\n",
    "        test_dataset = torchvision.datasets.ImageFolder(root='/home/baa223/Badri/deeplearning/dm_project/dm_project/PIE_32x32/test',\n",
    "                                                         transform=data_transform2)\n",
    "    else:\n",
    "        raise ValueError(\"Dataset not supported\")\n",
    "    \n",
    "    return train_dataset, test_dataset, visual_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the imagenet weights as a starting point\n",
    "auto_weights = torchvision.models.ResNet50_Weights.IMAGENET1K_V2\n",
    "\n",
    "# Defining the data augmentations for the dataset\n",
    "transform1 = [\n",
    "    transforms.RandomResizedCrop(32, interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.TrivialAugmentWide(interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.1)\n",
    "]\n",
    "\n",
    "transform2 = [\n",
    "    transforms.Resize((40, 40), interpolation=transforms.InterpolationMode.BILINEAR, antialias=True),\n",
    "    transforms.CenterCrop(32),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.ConvertImageDtype(torch.float),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test datasets\n",
    "train_dataset, test_dataset, visual_dataset = load_dataset(param['dataset_name'], transform1, transform2)\n",
    "\n",
    "# Using 10% of training dataset to create validation dataset\n",
    "val_size = int(0.1 * len(train_dataset))\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataloaders\n",
    "train_dl = DataLoader(train_dataset, batch_size=param['batch_size'], \n",
    "                      shuffle=True, num_workers=param['num_workers'])\n",
    "val_dl = DataLoader(val_dataset, batch_size=param['batch_size'], \n",
    "                    shuffle=False, num_workers=param['num_workers'])\n",
    "test_dl = DataLoader(test_dataset, batch_size=param['batch_size'], \n",
    "                     shuffle=False, num_workers=param['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(iter(train_dl))\n",
    "test_images, test_labels = next(iter(test_dl))\n",
    "\n",
    "# Displaying the shape of the images and labels\n",
    "print(f\"Train Images Shape: {train_images.shape}, Train Labels Shape: {train_labels.shape}\")\n",
    "print(f\"Test Images Shape: {test_images.shape}, Test Labels Shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a python function that takes in the dataset and shows us 6 random images\n",
    "def show_images(dataset):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        image, label = dataset[np.random.randint(0, len(dataset))]\n",
    "        plt.imshow(image.permute(1, 2, 0))\n",
    "        plt.title(f\"Class: {label}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Displaying 6 random images from the training dataset\n",
    "show_images(visual_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Load the model with the imagenet weights\n",
    "model1 = torchvision.models.resnet50(weights=auto_weights)\n",
    "# model1 = torchvision.models.resnet50()\n",
    "\n",
    "# freeze all the layers except the last layer\n",
    "# for params in model1.parameters():\n",
    "#     params.requires_grad = False\n",
    "\n",
    "# Change the last layer to output the number of classes in the dataset\n",
    "model1.fc = nn.Linear(in_features=model1.fc.in_features, out_features=param['classes'], bias=True)\n",
    "model1.to(device)\n",
    "summary(model1, input_size=(32, 3, 255, 255),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross entropy loss and Adam optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=param['lr'],\n",
    "                            weight_decay=param['weight_decay'])\n",
    "\n",
    "# Set up metrics dictionary to log loss, accuracy and f1 score\n",
    "metrics = {\"train_loss\": [],\n",
    "           \"train_acc\": [],\n",
    "           \"val_loss\": [],\n",
    "           \"val_acc\": [],\n",
    "           \"train_f1\": [],\n",
    "           \"val_f1\": []\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_acc = 0\n",
    "train_acc, train_loss = 0, 0\n",
    "\n",
    "for epoch in range(param['epochs']):\n",
    "    # training\n",
    "    model1.train()\n",
    "    # set up a progress bar\n",
    "    train_dl_progress = tqdm(enumerate(train_dl), total=len(train_dl),\n",
    "                                 bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]\")\n",
    "\n",
    "    train_acc, train_loss = 0, 0\n",
    "    # iterate over the training dataloader\n",
    "    for i, (images, labels) in train_dl_progress:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # get the model predictions\n",
    "        y_pred_logits = model1(images)\n",
    "        # get the class with the highest probability\n",
    "        y_pred = y_pred_logits.argmax(dim=1)\n",
    "        # calculate the f1 score\n",
    "        train_f1 = multiclass_f1_score(y_pred, labels, num_classes=param['classes'])\n",
    "\n",
    "        loss = loss_fn(y_pred_logits, labels)\n",
    "        # cumulate the loss and accuracy\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_acc += (y_pred == labels).sum().item() / len(y_pred_logits)\n",
    "        train_dl_progress.set_description(f\"Epoch: {epoch+1}/{param['epochs']}\")\n",
    "\n",
    "    # calculate the average loss and accuracy\n",
    "    train_acc /= len(train_dl)\n",
    "    train_loss /= len(train_dl)\n",
    "\n",
    "    # evaluation of validation dataset\n",
    "    model1.eval()\n",
    "    val_loss, val_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        # iterate over the validation dataloader\n",
    "        for val_images, val_labels in val_dl:\n",
    "            val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "\n",
    "            # get the model predictions\n",
    "            y_val_pred_logits = model1(val_images)\n",
    "            # get the class with the highest probability\n",
    "            y_val_pred = y_val_pred_logits.argmax(dim=1)\n",
    "\n",
    "            # cumulate the loss and accuracy\n",
    "            val_loss += loss_fn(y_val_pred_logits, val_labels)\n",
    "            val_acc += (y_val_pred == val_labels).sum().item()/len(y_val_pred_logits)\n",
    "            # caculate the f1 score\n",
    "            val_f1 = multiclass_f1_score(y_val_pred, val_labels, num_classes=param['classes'])\n",
    "\n",
    "        # calculate the average loss and accuracy\n",
    "        val_loss /= len(val_dl)\n",
    "        val_acc /= len(val_dl)\n",
    "\n",
    "        # save the model with the highest validation accuracy\n",
    "        if max_val_acc < val_acc:\n",
    "            max_val_acc = val_acc\n",
    "            print(f\"model saved with val accuracy of {val_acc*100:.6f}\")\n",
    "            torch.save(model1.state_dict(), f\"dm_project/{param['model_name']}.pt\")\n",
    "\n",
    "    # log the metrics\n",
    "    metrics[\"train_loss\"].append(train_loss.item()) # type: ignore\n",
    "    metrics[\"train_acc\"].append(train_acc)\n",
    "    metrics[\"val_loss\"].append(val_loss.item()) # type: ignore\n",
    "    metrics[\"val_acc\"].append(val_acc)\n",
    "    metrics[\"train_f1\"].append(train_f1.item())\n",
    "    metrics[\"val_f1\"].append(val_f1.item())\n",
    "    \n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc*100:.2f}%, '\n",
    "        f'Validation Accuracy: {val_acc*100:.2f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy and Loss graph of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph of loss and accuracy stored inside metrics dictionary\n",
    "# train and val loss of the model\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(metrics[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(metrics[\"val_loss\"], label=\"Val Loss\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "# train and val accuracy of the model\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(metrics[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(metrics[\"val_acc\"], label=\"Val Acc\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy vs Epochs\")\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle(f\"Performance of Resnet50 on {param['dataset_name']} dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance of the model on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the saved model with same architecture as the trained model\n",
    "saved_model = torchvision.models.resnet50()\n",
    "# Change the last layer to output the number of classes in the dataset\n",
    "saved_model.fc = nn.Linear(in_features=saved_model.fc.in_features, out_features=param['classes'], bias=True)\n",
    "\n",
    "# load the trained model weights\n",
    "saved_model.load_state_dict(torch.load(f\"dm_project/{param['model_name']}.pt\"))\n",
    "saved_model.to(device)\n",
    "\n",
    "test_loss, test_acc, test_auc = 0, 0, 0\n",
    "test_gt, test_pred = [], []\n",
    "\n",
    "# set the model to evaluation mode\n",
    "saved_model.eval()\n",
    "with torch.inference_mode():\n",
    "    # iterate over the test dataloader\n",
    "    for test_images, test_labels in test_dl:\n",
    "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "        # get the model predictions\n",
    "        y_test_pred_logits = saved_model(test_images)\n",
    "        y_test_pred = y_test_pred_logits.argmax(dim=1)\n",
    "\n",
    "        # store the ground truth and predictions as list for calculating AUC\n",
    "        test_gt.extend(list(test_labels.cpu().numpy()))\n",
    "        test_pred.extend(list(y_test_pred_logits.cpu().numpy()))\n",
    "\n",
    "        # cumulate the loss and accuracy\n",
    "        test_loss += loss_fn(y_test_pred_logits, test_labels)\n",
    "        test_acc += (y_test_pred == test_labels).sum().item()/len(y_test_pred_logits)\n",
    "        # calculate the f1 score\n",
    "        test_f1 = multiclass_f1_score(y_test_pred, test_labels, num_classes=param['classes'])\n",
    "        \n",
    "    # calculate the average loss and accuracy\n",
    "    test_loss /= len(test_dl)\n",
    "    test_acc /= len(test_dl)\n",
    "\n",
    "# convert the ground truth to one hot encoding\n",
    "test_gt = label_binarize(test_gt, classes=np.arange(param['classes']))\n",
    "# convert the predictions to a numpy array\n",
    "test_pred = [[float(num) for num in arr.tolist()] for arr in test_pred]\n",
    "test_pred = np.array(test_pred)\n",
    "\n",
    "# calculate the AUC score for each class\n",
    "auc_scores = []\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "for i in range(param['classes']):\n",
    "    fpr[i], tpr[i], _ = roc_curve(test_gt[:, i], test_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    auc_scores.append(roc_auc[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(param['classes']):\n",
    "    plt.plot(fpr[i], tpr[i], label='Class %d ROC curve (area = %0.2f)' % (i, roc_auc[i]))\n",
    "\n",
    "avg_auc = np.mean(auc_scores)\n",
    "\n",
    "\n",
    "# print the test loss, accuracy, f1 score and mean AUC\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f} | Test F1: {test_f1.item():.4f} | Mean Test AUC: {avg_auc:.4f}\")\n",
    "\n",
    "# plotting the auc of roc curves\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "if param['classes'] <= 10:\n",
    "    plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ground Truth vs Predicted Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that shows ground truth and predicted images for 6 random images\n",
    "# images will look a little odd because we are loading them from train dataset\n",
    "# which is using a lot of data augmentation techniques on these images.\n",
    "def show_gt_pred(model, dataset, vis_ds):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    for i in range(9):\n",
    "        plt.subplot(3, 3, i+1)\n",
    "        index = np.random.randint(0, len(dataset))\n",
    "        image, label = dataset[index]\n",
    "        plt.imshow(image.permute(1, 2, 0))\n",
    "        plt.title(f\"GT: {label}, Pred: {model(image.unsqueeze(0).to(device)).argmax().item()}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Displaying 6 random images from the test dataset with ground truth and predicted labels\n",
    "show_gt_pred(saved_model, train_dataset, visual_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the confusion matrix for the test dataset\n",
    "\n",
    "# get the confusion matrix\n",
    "conf_matrix = confusion_matrix(test_gt.argmax(axis=1), test_pred.argmax(axis=1)) # type: ignore\n",
    "\n",
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
